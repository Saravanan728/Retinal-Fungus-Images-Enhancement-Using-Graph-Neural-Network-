{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1OMyosq1ozuQ+hbYcxXpI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saravanan728/Retinal-Fungus-Images-Enhancement-Using-Graph-Neural-Network-/blob/main/Copy_of_Retinal_Fungus_Images_Enhancement_Using_Graph_Neural_Network_(GNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJJND6xN85dC"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    required_packages = [\n",
        "        'torch',\n",
        "        'torchvision',\n",
        "        'torchaudio',\n",
        "        'scikit-image',\n",
        "        'pandas',\n",
        "        'seaborn',\n",
        "        'matplotlib',\n",
        "        'opencv-python'\n",
        "    ]\n",
        "\n",
        "    # First install base packages\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    # Install PyTorch Geometric with dependencies\n",
        "    try:\n",
        "        from torch_geometric.data import Data\n",
        "    except ImportError:\n",
        "        import torch\n",
        "        TORCH_VERSION = torch.__version__.split('+')[0]\n",
        "        CUDA = 'cu' + torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "        # For PyTorch 2.6.0 with CUDA 12.4\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\",\n",
        "                             \"torch-scatter\", \"torch-sparse\", \"torch-cluster\", \"torch-spline-conv\",\n",
        "                             \"-f\", f\"https://data.pyg.org/whl/torch-{TORCH_VERSION}+{CUDA}.html\"])\n",
        "\n",
        "        # Install main package\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"torch-geometric\"])\n",
        "\n",
        "install_packages()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JvRpJ305_Y4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9o70PCrj9KND"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_packages():\n",
        "    required_packages = [\n",
        "        'torch',\n",
        "        'torchvision',\n",
        "        'torchaudio',\n",
        "        'scikit-image',\n",
        "        'pandas',\n",
        "        'seaborn',\n",
        "        'matplotlib',\n",
        "        'opencv-python-headless',\n",
        "        'opencv-contrib-python-headless',\n",
        "        'scikit-learn'\n",
        "    ]\n",
        "\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            __import__(package)\n",
        "        except ImportError:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "install_packages()\n",
        "\n",
        "# Main Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "from torch_geometric.nn.pool import knn_graph\n",
        "from skimage import feature, filters, exposure, color\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import mean_squared_error\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import traceback\n",
        "import warnings\n",
        "from scipy import ndimage\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class PerformanceMetrics:\n",
        "    @staticmethod\n",
        "    def compute_psnr(original, enhanced):\n",
        "        if original.shape != enhanced.shape:\n",
        "            enhanced = cv2.resize(enhanced, (original.shape[1], original.shape[0]))\n",
        "        return psnr(original, enhanced, data_range=1.0)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_ssim(original, enhanced):\n",
        "        if original.shape != enhanced.shape:\n",
        "            enhanced = cv2.resize(enhanced, (original.shape[1], original.shape[0]))\n",
        "        return ssim(original, enhanced, data_range=1.0, channel_axis=2 if original.ndim == 3 else None)\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_mae(original, enhanced):\n",
        "        if original.shape != enhanced.shape:\n",
        "            enhanced = cv2.resize(enhanced, (original.shape[1], original.shape[0]))\n",
        "        return np.mean(np.abs(original - enhanced))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_nrmse(original, enhanced):\n",
        "        if original.shape != enhanced.shape:\n",
        "            enhanced = cv2.resize(enhanced, (original.shape[1], original.shape[0]))\n",
        "        mse = mean_squared_error(original, enhanced)\n",
        "        return np.sqrt(mse) / (np.max(original) - np.min(original))\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_all_metrics(original, processed):\n",
        "        return {\n",
        "            'PSNR': PerformanceMetrics.compute_psnr(original, processed),\n",
        "            'SSIM': PerformanceMetrics.compute_ssim(original, processed),\n",
        "            'MAE': PerformanceMetrics.compute_mae(original, processed),\n",
        "            'NRMSE': PerformanceMetrics.compute_nrmse(original, processed)\n",
        "        }\n",
        "\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        self.input_dir = '/content/drive/MyDrive/gan/train'\n",
        "        self.output_dir = '/content/drive/MyDrive/improved_gnn_modal_finalized'\n",
        "\n",
        "        self.subdirs = {\n",
        "            'grayscale': 'grayscale',\n",
        "            'enhanced': 'enhanced',\n",
        "            'vessel': 'vessel_enhanced',\n",
        "            'gnn': 'gnn_enhanced',\n",
        "            'color': 'color_restored',\n",
        "            'final': 'final_output',\n",
        "            'comparisons': 'comparisons',\n",
        "            'metrics': 'performance_metrics'\n",
        "        }\n",
        "\n",
        "        # Model parameters\n",
        "        self.num_node_features = 32\n",
        "        self.gnn_hidden_channels = 128\n",
        "        self.gnn_output_channels = 64\n",
        "        self.patch_size = 9\n",
        "        self.graph_step = 4\n",
        "        self.knn_k = 8\n",
        "\n",
        "        # Training parameters\n",
        "        self.batch_size = 2\n",
        "        self.epochs = 30\n",
        "        self.learning_rate = 0.0001\n",
        "        self.dropout_rate = 0.2\n",
        "\n",
        "        # Image processing\n",
        "        self.frangi_sigmas = (1, 2, 3)\n",
        "        self.clip_limit = 0.03\n",
        "\n",
        "        self._create_directories()\n",
        "        self.metrics_df = pd.DataFrame(columns=[\n",
        "            'Image', 'Original_PSNR', 'Original_SSIM', 'Original_MAE', 'Original_NRMSE',\n",
        "            'Enhanced_PSNR', 'Enhanced_SSIM', 'Enhanced_MAE', 'Enhanced_NRMSE',\n",
        "            'GNN_PSNR', 'GNN_SSIM', 'GNN_MAE', 'GNN_NRMSE',\n",
        "            'Final_PSNR', 'Final_SSIM', 'Final_MAE', 'Final_NRMSE'\n",
        "        ])\n",
        "\n",
        "    def _create_directories(self):\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "        for name, subdir in self.subdirs.items():\n",
        "            path = os.path.join(self.output_dir, subdir)\n",
        "            os.makedirs(path, exist_ok=True)\n",
        "\n",
        "class ImageProcessor:\n",
        "    @staticmethod\n",
        "    def to_grayscale(img):\n",
        "        return color.rgb2gray(img)\n",
        "\n",
        "    @staticmethod\n",
        "    def enhance_contrast(img, clip_limit=0.03):\n",
        "        return exposure.equalize_adapthist(img, clip_limit=clip_limit)\n",
        "\n",
        "    @staticmethod\n",
        "    def extract_vessels(img, sigmas=(1, 2, 3)):\n",
        "        vessel_maps = []\n",
        "        weights = [0.3, 0.4, 0.3]\n",
        "        for sigma, weight in zip(sigmas, weights):\n",
        "            vessel_map = filters.frangi(img, sigmas=[sigma], black_ridges=False)\n",
        "            vessel_maps.append(vessel_map * weight)\n",
        "        return np.sum(vessel_maps, axis=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def restore_color(grayscale_img, original_img):\n",
        "        lab = color.rgb2lab(original_img)\n",
        "        L = grayscale_img * 100\n",
        "        a = cv2.bilateralFilter(lab[:, :, 1].astype(np.float32), d=9, sigmaColor=0.2, sigmaSpace=9)\n",
        "        b = cv2.bilateralFilter(lab[:, :, 2].astype(np.float32), d=9, sigmaColor=0.2, sigmaSpace=9)\n",
        "        return np.clip(color.lab2rgb(np.stack([L, a, b], axis=2)), 0, 1)\n",
        "\n",
        "class EnhancedGNNModel(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.conv1 = GCNConv(config.num_node_features, config.gnn_hidden_channels)\n",
        "        self.conv2 = GCNConv(config.gnn_hidden_channels, config.gnn_hidden_channels)\n",
        "        self.conv3 = GCNConv(config.gnn_hidden_channels, config.gnn_hidden_channels)\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.Linear(config.gnn_hidden_channels, config.gnn_hidden_channels // 2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Linear(config.gnn_hidden_channels // 2, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(config.gnn_hidden_channels, config.gnn_hidden_channels // 2)\n",
        "        self.fc2 = nn.Linear(config.gnn_hidden_channels // 2, config.gnn_output_channels)\n",
        "        self.fc3 = nn.Linear(config.gnn_output_channels, 1)\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(config.gnn_hidden_channels)\n",
        "        self.bn2 = nn.BatchNorm1d(config.gnn_hidden_channels)\n",
        "        self.dropout = nn.Dropout(config.dropout_rate)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        x1 = F.leaky_relu(self.conv1(x, edge_index), negative_slope=0.2)\n",
        "        x1 = self.bn1(x1)\n",
        "        x1 = self.dropout(x1)\n",
        "\n",
        "        x2 = F.leaky_relu(self.conv2(x1, edge_index), negative_slope=0.2)\n",
        "        x2 = self.bn2(x2 + x1)\n",
        "        x2 = self.dropout(x2)\n",
        "\n",
        "        x3 = F.leaky_relu(self.conv3(x2, edge_index), negative_slope=0.2)\n",
        "        attn = self.attention(x3)\n",
        "        x3 = x3 * attn\n",
        "\n",
        "        x_pool = global_mean_pool(x3, batch)\n",
        "\n",
        "        x = F.leaky_relu(self.fc1(x_pool), negative_slope=0.2)\n",
        "        x = self.dropout(x)\n",
        "        x = F.leaky_relu(self.fc2(x), negative_slope=0.2)\n",
        "        x = self.dropout(x)\n",
        "        return torch.sigmoid(self.fc3(x))\n",
        "\n",
        "class RetinalGraphDataset(Dataset):\n",
        "    def __init__(self, img_dir, config, num_samples=None):\n",
        "        self.config = config\n",
        "        self.image_files = self._get_image_files(img_dir, num_samples)\n",
        "        self.scaler = MinMaxScaler()\n",
        "\n",
        "    def _get_image_files(self, img_dir, num_samples):\n",
        "        image_files = []\n",
        "        for root, _, files in os.walk(img_dir):\n",
        "            for f in files:\n",
        "                if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    full_path = os.path.join(root, f)\n",
        "                    img = cv2.imread(full_path)\n",
        "                    if img is not None:\n",
        "                        image_files.append(full_path)\n",
        "                        if num_samples and len(image_files) >= num_samples:\n",
        "                            break\n",
        "        return image_files[:num_samples] if num_samples else image_files\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_files[idx]\n",
        "        img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "        grayscale = ImageProcessor.to_grayscale(img)\n",
        "        enhanced = ImageProcessor.enhance_contrast(grayscale, self.config.clip_limit)\n",
        "        vessels = ImageProcessor.extract_vessels(enhanced, self.config.frangi_sigmas)\n",
        "        return self._create_graph(enhanced, vessels, grayscale)\n",
        "\n",
        "    def _create_graph(self, enhanced_img, vessel_img, grayscale_img):\n",
        "        h, w = enhanced_img.shape\n",
        "        step = self.config.graph_step\n",
        "        patch_size = self.config.patch_size\n",
        "\n",
        "        features, positions = [], []\n",
        "        for i in range(0, h, step):\n",
        "            for j in range(0, w, step):\n",
        "                patch = enhanced_img[\n",
        "                    max(0, i-patch_size//2):min(h, i+patch_size//2+1),\n",
        "                    max(0, j-patch_size//2):min(w, j+patch_size//2+1)\n",
        "                ]\n",
        "                patch_uint8 = (patch * 255).astype(np.uint8)\n",
        "\n",
        "                # Base features\n",
        "                feat = [\n",
        "                    enhanced_img[i, j], vessel_img[i, j], grayscale_img[i, j],\n",
        "                    np.mean(patch), np.std(patch), np.max(patch)-np.min(patch),\n",
        "                    filters.sobel(patch).mean(), i/h, j/w,\n",
        "                    *np.histogram(patch, bins=5, range=(0, 1))[0],\n",
        "                    *feature.local_binary_pattern(patch, 8, 1).flatten()[:15]\n",
        "                ]\n",
        "\n",
        "                # Texture features using graycomatrix\n",
        "                try:\n",
        "                    from skimage.feature import graycomatrix, graycoprops\n",
        "                    glcm = graycomatrix(patch_uint8, [1], [0], symmetric=True, normed=True)\n",
        "                    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "                    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
        "                    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "                    feat.extend([contrast, dissimilarity, homogeneity])\n",
        "                except:\n",
        "                    # Fallback features\n",
        "                    feat.extend([patch.mean(), patch.std(), patch.var()])\n",
        "\n",
        "                feat = feat[:self.config.num_node_features]\n",
        "                if len(feat) < self.config.num_node_features:\n",
        "                    feat += [0]*(self.config.num_node_features - len(feat))\n",
        "                features.append(feat)\n",
        "                positions.append([i, j])\n",
        "\n",
        "        features = self.scaler.fit_transform(np.array(features))\n",
        "        edge_index = knn_graph(\n",
        "            torch.tensor(np.array(positions), dtype=torch.float),\n",
        "            k=self.config.knn_k,\n",
        "            loop=True\n",
        "        )\n",
        "\n",
        "        return Data(\n",
        "            x=torch.tensor(features, dtype=torch.float32),\n",
        "            edge_index=edge_index,\n",
        "            original_shape=(h, w),\n",
        "            pos=torch.tensor(positions, dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "class EnhancedRetinalPipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.processor = ImageProcessor()\n",
        "        self.metrics = PerformanceMetrics()\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.dataset = RetinalGraphDataset(config.input_dir, config)\n",
        "        if len(self.dataset) == 0:\n",
        "            raise ValueError(\"No images found in directory\")\n",
        "\n",
        "    def train_gnn(self):\n",
        "        loader = DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=self.config.batch_size,\n",
        "            shuffle=True,\n",
        "            collate_fn=lambda batch: Batch.from_data_list(batch)\n",
        "        )\n",
        "\n",
        "        model = EnhancedGNNModel(self.config).to(self.device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=self.config.learning_rate, weight_decay=1e-5)\n",
        "        criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([5.0]).to(self.device))\n",
        "\n",
        "        best_loss = float('inf')\n",
        "        patience = 5\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(1, self.config.epochs + 1):\n",
        "            model.train()\n",
        "            total_loss = 0.0\n",
        "\n",
        "            for batch in tqdm(loader, desc=f\"Epoch {epoch}/{self.config.epochs}\"):\n",
        "                batch = batch.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                out = model(batch)\n",
        "                target = global_mean_pool(batch.x[:, 1].unsqueeze(1), batch.batch)\n",
        "\n",
        "                loss = criterion(out, target)\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "                optimizer.step()\n",
        "                total_loss += loss.item()\n",
        "\n",
        "            avg_loss = total_loss / len(loader)\n",
        "            if avg_loss < best_loss:\n",
        "                best_loss = avg_loss\n",
        "                patience_counter = 0\n",
        "                torch.save(model.state_dict(), os.path.join(self.config.output_dir, 'best_model.pth'))\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "                if patience_counter >= patience:\n",
        "                    print(f\"Early stopping at epoch {epoch}\")\n",
        "                    break\n",
        "\n",
        "            print(f'Epoch {epoch}, Loss: {avg_loss:.4f}, Best Loss: {best_loss:.4f}')\n",
        "\n",
        "        model.load_state_dict(torch.load(os.path.join(self.config.output_dir, 'best_model.pth')))\n",
        "        return model\n",
        "\n",
        "    def process_image(self, img_path, model):\n",
        "        try:\n",
        "            img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB).astype(np.float32) / 255.0\n",
        "            filename = os.path.basename(img_path)\n",
        "\n",
        "            grayscale = self.processor.to_grayscale(img)\n",
        "            enhanced = self.processor.enhance_contrast(grayscale, self.config.clip_limit)\n",
        "            vessels = self.processor.extract_vessels(enhanced, self.config.frangi_sigmas)\n",
        "\n",
        "            graph = self.dataset._create_graph(enhanced, vessels, grayscale)\n",
        "            h, w = graph.original_shape\n",
        "\n",
        "            graph = graph.to(self.device)\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                output = model(graph)\n",
        "\n",
        "            # Get nodes and output values\n",
        "            nodes = graph.pos.cpu().numpy()\n",
        "            output_values = output.cpu().numpy().reshape(-1)\n",
        "\n",
        "            # Ensure matching dimensions\n",
        "            if len(nodes) != len(output_values):\n",
        "                min_len = min(len(nodes), len(output_values))\n",
        "                nodes = nodes[:min_len]\n",
        "                output_values = output_values[:min_len]\n",
        "\n",
        "            # Create grid for interpolation\n",
        "            grid_x, grid_y = np.mgrid[0:h, 0:w]\n",
        "\n",
        "            # Use nearest neighbor interpolation for stability\n",
        "            gnn_output = griddata(\n",
        "                nodes[:, :2],\n",
        "                output_values,\n",
        "                (grid_x, grid_y),\n",
        "                method='nearest',  # Changed to nearest neighbor for stability\n",
        "                fill_value=0\n",
        "            )\n",
        "\n",
        "            vessel_mask = (vessels > 0.2).astype(float)\n",
        "            gnn_enhanced = enhanced * (1 - vessel_mask) + (enhanced + gnn_output * 0.7) * vessel_mask\n",
        "            gnn_enhanced = np.clip(gnn_enhanced, 0, 1)\n",
        "\n",
        "            final = self.processor.restore_color(gnn_enhanced, img)\n",
        "\n",
        "            self._save_outputs(filename, grayscale, enhanced, vessels, gnn_enhanced, final)\n",
        "            self._save_comparison(filename, img, grayscale, enhanced, vessels, gnn_enhanced, final)\n",
        "\n",
        "            metrics = {\n",
        "                'Image': filename,\n",
        "                **PerformanceMetrics.compute_all_metrics(img, img),\n",
        "                **{'Enhanced_'+k: v for k,v in PerformanceMetrics.compute_all_metrics(img, self.processor.restore_color(enhanced, img)).items()},\n",
        "                **{'GNN_'+k: v for k,v in PerformanceMetrics.compute_all_metrics(img, self.processor.restore_color(gnn_enhanced, img)).items()},\n",
        "                **{'Final_'+k: v for k,v in PerformanceMetrics.compute_all_metrics(img, final).items()}\n",
        "            }\n",
        "            self.config.metrics_df.loc[len(self.config.metrics_df)] = metrics\n",
        "\n",
        "            return final\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {os.path.basename(img_path)}: {str(e)}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    def _save_outputs(self, filename, *images):\n",
        "        names = ['grayscale', 'enhanced', 'vessel', 'gnn', 'final']\n",
        "        for name, img in zip(names, images):\n",
        "            output_path = os.path.join(self.config.output_dir, self.config.subdirs[name], filename)\n",
        "            if img.ndim == 2:\n",
        "                cv2.imwrite(output_path, (img * 255).astype(np.uint8))\n",
        "            else:\n",
        "                cv2.imwrite(output_path, cv2.cvtColor((img * 255).astype(np.uint8), cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    def _save_comparison(self, filename, original, *processed_images):\n",
        "        enhanced_color = self.processor.restore_color(processed_images[1], original)\n",
        "        gnn_enhanced_color = self.processor.restore_color(processed_images[3], original)\n",
        "\n",
        "        titles = ['Original', 'Grayscale', 'Enhanced', 'Vessels', 'GNN Enhanced', 'Final',\n",
        "                 'Enhanced Color', 'GNN Enhanced Color']\n",
        "        fig, axes = plt.subplots(2, 4, figsize=(24, 12))\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for ax, img, title in zip(axes,\n",
        "                                [original, processed_images[0], processed_images[1],\n",
        "                                processed_images[2], processed_images[3], processed_images[4],\n",
        "                                enhanced_color, gnn_enhanced_color],\n",
        "                                titles):\n",
        "            ax.imshow(img, cmap='gray' if img.ndim == 2 else None)\n",
        "            ax.set_title(title)\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(self.config.output_dir, self.config.subdirs['comparisons'], filename))\n",
        "        plt.close()\n",
        "\n",
        "    def _plot_metrics(self):\n",
        "        df = self.config.metrics_df\n",
        "        metrics = ['PSNR', 'SSIM', 'MAE', 'NRMSE']\n",
        "\n",
        "        # Create individual plots for each metric\n",
        "        for metric in metrics:\n",
        "            plt.figure(figsize=(10, 6))\n",
        "\n",
        "            # Get values for Enhanced and GNN methods\n",
        "            enhanced_vals = df[f'Enhanced_{metric}']\n",
        "            gnn_vals = df[f'GNN_{metric}']\n",
        "\n",
        "            # Create bar positions\n",
        "            x = np.arange(len(df))\n",
        "            width = 0.35\n",
        "\n",
        "            # Plot bars\n",
        "            plt.bar(x - width/2, enhanced_vals, width, label='Enhanced', alpha=0.7)\n",
        "            plt.bar(x + width/2, gnn_vals, width, label='GNN Enhanced', alpha=0.7)\n",
        "\n",
        "            # Customize plot\n",
        "            plt.xlabel('Image Index')\n",
        "            plt.ylabel(metric)\n",
        "            plt.title(f'{metric} Comparison: Enhanced vs GNN Enhanced')\n",
        "            plt.xticks(x, df['Image'], rotation=45, ha='right')\n",
        "            plt.legend()\n",
        "            plt.grid(True, alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save and show\n",
        "            plt.savefig(os.path.join(self.config.output_dir, f'{metric.lower()}_comparison.png'))\n",
        "            plt.show()\n",
        "\n",
        "        # Also save the combined metrics plot\n",
        "        self._plot_combined_metrics()\n",
        "\n",
        "    def _plot_combined_metrics(self):\n",
        "        df = self.config.metrics_df\n",
        "        metrics = ['PSNR', 'SSIM', 'MAE', 'NRMSE']\n",
        "\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        x = np.arange(len(metrics))\n",
        "        width = 0.25\n",
        "\n",
        "        for i, method in enumerate(['Enhanced', 'GNN', 'Final']):\n",
        "            values = []\n",
        "            for metric in metrics:\n",
        "                if metric in ['MAE', 'NRMSE']:\n",
        "                    values.append(1 - df[f'{method}_{metric}'].mean())\n",
        "                else:\n",
        "                    values.append(df[f'{method}_{metric}'].mean())\n",
        "            plt.bar(x + (i-1)*width, values, width, label=method)\n",
        "\n",
        "        plt.xlabel('Metrics')\n",
        "        plt.ylabel('Score (Higher is better)')\n",
        "        plt.title('Performance Comparison')\n",
        "        plt.xticks(x, metrics)\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.savefig(os.path.join(self.config.output_dir, 'metrics_comparison.png'))\n",
        "        plt.show()\n",
        "\n",
        "  def process_all_images(self):        print(f\"Processing {len(self.dataset)} images\")\n",
        "        model = self.train_gnn()\n",
        "\n",
        "        for img_path in tqdm(self.dataset.image_files, desc=\"Processing\"):\n",
        "            self.process_image(img_path, model)\n",
        "\n",
        "        self.config.metrics_df.to_csv(os.path.join(self.config.output_dir, 'metrics.csv'), index=False)\n",
        "        self._plot_metrics()\n",
        "        print(\"Pipeline completed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    config = Config()\n",
        "    pipeline = EnhancedRetinalPipeline(config)\n",
        "    pipeline.process_all_images()"
      ],
      "metadata": {
        "id": "cMEStMVy9LyE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
